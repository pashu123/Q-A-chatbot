{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainingRnn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZGWQRHFoV8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "bc408a2b-bfff-46b0-a401-2fe4533fde69"
      },
      "source": [
        "!git clone https://github.com/pashu123/Q-A-chatbot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Q-A-chatbot'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)   \u001b[K\rremote: Counting objects:  18% (2/11)   \u001b[K\rremote: Counting objects:  27% (3/11)   \u001b[K\rremote: Counting objects:  36% (4/11)   \u001b[K\rremote: Counting objects:  45% (5/11)   \u001b[K\rremote: Counting objects:  54% (6/11)   \u001b[K\rremote: Counting objects:  63% (7/11)   \u001b[K\rremote: Counting objects:  72% (8/11)   \u001b[K\rremote: Counting objects:  81% (9/11)   \u001b[K\rremote: Counting objects:  90% (10/11)   \u001b[K\rremote: Counting objects: 100% (11/11)   \u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)   \u001b[K\rremote: Compressing objects:  18% (2/11)   \u001b[K\rremote: Compressing objects:  27% (3/11)   \u001b[K\rremote: Compressing objects:  36% (4/11)   \u001b[K\rremote: Compressing objects:  45% (5/11)   \u001b[K\rremote: Compressing objects:  54% (6/11)   \u001b[K\rremote: Compressing objects:  63% (7/11)   \u001b[K\rremote: Compressing objects:  72% (8/11)   \u001b[K\rremote: Compressing objects:  81% (9/11)   \u001b[K\rremote: Compressing objects:  90% (10/11)   \u001b[K\rremote: Compressing objects: 100% (11/11)   \u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "Unpacking objects:   9% (1/11)   \rUnpacking objects:  18% (2/11)   \rUnpacking objects:  27% (3/11)   \rUnpacking objects:  36% (4/11)   \rUnpacking objects:  45% (5/11)   \rUnpacking objects:  54% (6/11)   \rremote: Total 11 (delta 2), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  63% (7/11)   \rUnpacking objects:  72% (8/11)   \rUnpacking objects:  81% (9/11)   \rUnpacking objects:  90% (10/11)   \rUnpacking objects: 100% (11/11)   \rUnpacking objects: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGFpK-e8WNdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "555b0199-361e-4f60-da69-f24d70f2d027"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mQ-A-chatbot\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjL3VUlqWQ_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a2adb4c-63d2-4eeb-a5d6-4747c4a9c1e2"
      },
      "source": [
        "cd Q-A-chatbot/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Q-A-chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXADBWbLWSh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47783613-b6ba-4623-b9a6-62800f32f21a"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "README.md  test_qa.txt  train_qa.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZKhXCtWWTHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwaMWbbwWVVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('train_qa.txt','rb') as f:\n",
        "  train_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWsZrXZ4WeXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test_qa.txt','rb') as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew60WX2IWiNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = test_data + train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgPoC-qaWjlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21da3a95-8ab7-405e-a913-cc629f5e418a"
      },
      "source": [
        "len(all_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORwzOgrXMx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for story,question,answer in all_data:\n",
        "  vocab = vocab.union(set(story))\n",
        "  vocab = vocab.union(set(question))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn1Xme7wYkxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XWKQgS6YrHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f9748e8-eade-42ff-d3b5-e1bb5f3193f2"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDmayBR4YsEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(vocab)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fWlEv2QY5lL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2024aa3f-2d6f-4416-b08e-0126702c5284"
      },
      "source": [
        "vocab_len"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVaK5cIuY7Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_story_lens = [len(data[0]) for data in all_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3dDXBrUZMy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b4909be-afd7-4c21-edd2-3db3666a9ea9"
      },
      "source": [
        "max(all_story_lens)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ApoW5AZOoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_story_len = max(all_story_lens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY_jvGNaZVcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MKwr5MGZivE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7550fcb6-5783-424a-92de-148ce1060517"
      },
      "source": [
        "max_question_len"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRDS-D31Zs7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5daaee68-ce0f-42a7-f201-7a4069881493"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwPQkMq3aG0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(filters = [])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX0jbal2aOWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b77a8d3-d5ba-463a-f10f-4e9e9f2e7aa6"
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5EyTXdmaVQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz0Luos3aiOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for story,question,answer in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_question_text.append(question)\n",
        "  train_answers.append(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyJBWVakax2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMztueoFa8gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data,word_index = tokenizer.word_index,max_story_len = max_story_len,max_question_len = max_question_len):\n",
        "  #stories\n",
        "  X = []\n",
        "  #question\n",
        "  Xq = []\n",
        "  # Y correct answer\n",
        "  Y = []\n",
        "  for story,query,answer in data:\n",
        "    x = [word_index[word.lower()] for word in story]\n",
        "    xq = [word_index[word.lower()] for word in query]\n",
        "    y = np.zeros(len(word_index)+1)\n",
        "    y[word_index[answer]] = 1\n",
        "    \n",
        "    X.append(x)\n",
        "    Xq.append(xq)\n",
        "    Y.append(y)\n",
        "  return (pad_sequences(X,maxlen = max_story_len),pad_sequences(Xq,maxlen = max_question_len),np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQX_FFBHd9mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train,queries_train,answers_train = vectorize_stories(train_data)\n",
        "inputs_test,queries_test,answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOmjUJVDeKRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82cacf7d-4120-4946-923a-c057586e857e"
      },
      "source": [
        "tokenizer.word_index['no']"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cj7FDvTeRQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the neural network\n",
        "## input encoder M\n",
        "## input encoder C\n",
        "## question encoder\n",
        "\n",
        "# Complete the network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_iI6ebYe-Uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input,Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrNxmTntfR3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# placeholder shape = (max_story_len,batch_size)\n",
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yBI4J1TfoqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocab_len\n",
        "vocab_size = len(vocab)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ydS5uHwfs2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input encoder M\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim= vocab_size,output_dim = 64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHTXAvNLgBpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim= vocab_size,output_dim = max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJvfxnhgMK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim= vocab_size,output_dim = 64,input_length = max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "\n",
        "#(samples,query_maxlen,embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz8A21j0ghNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoded <--- ENCODER(input)\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6mRQbEnhJ9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = dot([input_encoded_m,question_encoded],axes = (2,2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljtlt2M5hVG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = add([match,input_encoded_c])\n",
        "response = Permute((2,1))(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eINx7t9YhfTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = concatenate([response,question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Szki_LitKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c54ed0da-f6e3-42bc-cd0c-24a27ae2d0dc"
      },
      "source": [
        "answer"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-iF5i76iuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = LSTM(32)(answer)\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "model = Model([input_sequence,question],answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICVtdk2UjD4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqParr8_jKr9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "66bf317b-e3e7-4aab-e811-097710a0986b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_7 (Sequential)       multiple             2432        input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_9 (Sequential)       (None, 6, 64)        2432        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_3 (Dot)                     (None, 156, 6)       0           sequential_7[2][0]               \n",
            "                                                                 sequential_9[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 156, 6)       0           dot_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_8 (Sequential)       multiple             228         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 156, 6)       0           activation_3[0][0]               \n",
            "                                                                 sequential_8[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_9[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b4_JbWSjTST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4524
        },
        "outputId": "0e5f1366-3a97-426a-fc7e-a15ad17474e9"
      },
      "source": [
        "history = model.fit([inputs_train,queries_train],answers_train,batch_size = 32,epochs = 120,validation_data = ([inputs_test,queries_test],answers_test))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/120\n",
            "10000/10000 [==============================] - 8s 782us/step - loss: 0.8897 - acc: 0.4975 - val_loss: 0.6950 - val_acc: 0.4970\n",
            "Epoch 2/120\n",
            "10000/10000 [==============================] - 5s 506us/step - loss: 0.7070 - acc: 0.4868 - val_loss: 0.6936 - val_acc: 0.5030\n",
            "Epoch 3/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.6966 - acc: 0.4927 - val_loss: 0.6932 - val_acc: 0.5030\n",
            "Epoch 4/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.6943 - acc: 0.5031 - val_loss: 0.6936 - val_acc: 0.5030\n",
            "Epoch 5/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.6945 - acc: 0.5039 - val_loss: 0.6953 - val_acc: 0.4970\n",
            "Epoch 6/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.6946 - acc: 0.5024 - val_loss: 0.6934 - val_acc: 0.4970\n",
            "Epoch 7/120\n",
            "10000/10000 [==============================] - 5s 496us/step - loss: 0.6941 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.5030\n",
            "Epoch 8/120\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 0.6947 - acc: 0.4965 - val_loss: 0.6936 - val_acc: 0.4970\n",
            "Epoch 9/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.6945 - acc: 0.4947 - val_loss: 0.6935 - val_acc: 0.4970\n",
            "Epoch 10/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.6935 - acc: 0.5041 - val_loss: 0.6925 - val_acc: 0.5170\n",
            "Epoch 11/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.6883 - acc: 0.5343 - val_loss: 0.6867 - val_acc: 0.5140\n",
            "Epoch 12/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.6703 - acc: 0.5821 - val_loss: 0.6541 - val_acc: 0.6260\n",
            "Epoch 13/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.6546 - acc: 0.6253 - val_loss: 0.6468 - val_acc: 0.6410\n",
            "Epoch 14/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.6463 - acc: 0.6303 - val_loss: 0.6302 - val_acc: 0.6530\n",
            "Epoch 15/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.6335 - acc: 0.6468 - val_loss: 0.6163 - val_acc: 0.6580\n",
            "Epoch 16/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.6138 - acc: 0.6688 - val_loss: 0.5942 - val_acc: 0.6920\n",
            "Epoch 17/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.5869 - acc: 0.6900 - val_loss: 0.5637 - val_acc: 0.7030\n",
            "Epoch 18/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.5667 - acc: 0.7078 - val_loss: 0.5518 - val_acc: 0.7050\n",
            "Epoch 19/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.5507 - acc: 0.7138 - val_loss: 0.5271 - val_acc: 0.7300\n",
            "Epoch 20/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.5380 - acc: 0.7217 - val_loss: 0.5684 - val_acc: 0.6960\n",
            "Epoch 21/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.5383 - acc: 0.7228 - val_loss: 0.5365 - val_acc: 0.7260\n",
            "Epoch 22/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.5290 - acc: 0.7282 - val_loss: 0.5225 - val_acc: 0.7220\n",
            "Epoch 23/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.5219 - acc: 0.7371 - val_loss: 0.5215 - val_acc: 0.7250\n",
            "Epoch 24/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.5157 - acc: 0.7372 - val_loss: 0.5295 - val_acc: 0.7340\n",
            "Epoch 25/120\n",
            "10000/10000 [==============================] - 5s 497us/step - loss: 0.5112 - acc: 0.7425 - val_loss: 0.5177 - val_acc: 0.7320\n",
            "Epoch 26/120\n",
            "10000/10000 [==============================] - 5s 484us/step - loss: 0.5055 - acc: 0.7466 - val_loss: 0.5260 - val_acc: 0.7170\n",
            "Epoch 27/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.4907 - acc: 0.7622 - val_loss: 0.5106 - val_acc: 0.7560\n",
            "Epoch 28/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.4729 - acc: 0.7829 - val_loss: 0.4857 - val_acc: 0.7830\n",
            "Epoch 29/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.4503 - acc: 0.7964 - val_loss: 0.4770 - val_acc: 0.7850\n",
            "Epoch 30/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.4369 - acc: 0.8089 - val_loss: 0.4501 - val_acc: 0.7940\n",
            "Epoch 31/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.4158 - acc: 0.8233 - val_loss: 0.4360 - val_acc: 0.8060\n",
            "Epoch 32/120\n",
            "10000/10000 [==============================] - 5s 509us/step - loss: 0.4021 - acc: 0.8276 - val_loss: 0.4242 - val_acc: 0.8170\n",
            "Epoch 33/120\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 0.3964 - acc: 0.8331 - val_loss: 0.4161 - val_acc: 0.8210\n",
            "Epoch 34/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3889 - acc: 0.8376 - val_loss: 0.4101 - val_acc: 0.8190\n",
            "Epoch 35/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.3857 - acc: 0.8354 - val_loss: 0.4167 - val_acc: 0.8210\n",
            "Epoch 36/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3779 - acc: 0.8397 - val_loss: 0.4086 - val_acc: 0.8130\n",
            "Epoch 37/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.3730 - acc: 0.8441 - val_loss: 0.4303 - val_acc: 0.8160\n",
            "Epoch 38/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3707 - acc: 0.8440 - val_loss: 0.4095 - val_acc: 0.8150\n",
            "Epoch 39/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3673 - acc: 0.8450 - val_loss: 0.4027 - val_acc: 0.8280\n",
            "Epoch 40/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.3667 - acc: 0.8474 - val_loss: 0.4010 - val_acc: 0.8160\n",
            "Epoch 41/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3638 - acc: 0.8455 - val_loss: 0.4168 - val_acc: 0.8200\n",
            "Epoch 42/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.3539 - acc: 0.8488 - val_loss: 0.4019 - val_acc: 0.8290\n",
            "Epoch 43/120\n",
            "10000/10000 [==============================] - 5s 495us/step - loss: 0.3531 - acc: 0.8530 - val_loss: 0.4036 - val_acc: 0.8170\n",
            "Epoch 44/120\n",
            "10000/10000 [==============================] - 5s 477us/step - loss: 0.3530 - acc: 0.8476 - val_loss: 0.4097 - val_acc: 0.8180\n",
            "Epoch 45/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3531 - acc: 0.8518 - val_loss: 0.4000 - val_acc: 0.8260\n",
            "Epoch 46/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.3477 - acc: 0.8542 - val_loss: 0.4040 - val_acc: 0.8160\n",
            "Epoch 47/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3430 - acc: 0.8506 - val_loss: 0.4039 - val_acc: 0.8260\n",
            "Epoch 48/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3421 - acc: 0.8551 - val_loss: 0.4044 - val_acc: 0.8260\n",
            "Epoch 49/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3433 - acc: 0.8562 - val_loss: 0.3955 - val_acc: 0.8290\n",
            "Epoch 50/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3352 - acc: 0.8526 - val_loss: 0.3954 - val_acc: 0.8290\n",
            "Epoch 51/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3323 - acc: 0.8592 - val_loss: 0.3969 - val_acc: 0.8270\n",
            "Epoch 52/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3276 - acc: 0.8597 - val_loss: 0.3972 - val_acc: 0.8290\n",
            "Epoch 53/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3290 - acc: 0.8615 - val_loss: 0.4001 - val_acc: 0.8290\n",
            "Epoch 54/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.3266 - acc: 0.8644 - val_loss: 0.4026 - val_acc: 0.8180\n",
            "Epoch 55/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.3199 - acc: 0.8661 - val_loss: 0.4054 - val_acc: 0.8270\n",
            "Epoch 56/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.3232 - acc: 0.8627 - val_loss: 0.3903 - val_acc: 0.8270\n",
            "Epoch 57/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3176 - acc: 0.8635 - val_loss: 0.3924 - val_acc: 0.8300\n",
            "Epoch 58/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3174 - acc: 0.8645 - val_loss: 0.3999 - val_acc: 0.8300\n",
            "Epoch 59/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3160 - acc: 0.8674 - val_loss: 0.3970 - val_acc: 0.8310\n",
            "Epoch 60/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.3210 - acc: 0.8618 - val_loss: 0.3866 - val_acc: 0.8240\n",
            "Epoch 61/120\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 0.3141 - acc: 0.8673 - val_loss: 0.4041 - val_acc: 0.8220\n",
            "Epoch 62/120\n",
            "10000/10000 [==============================] - 5s 491us/step - loss: 0.3095 - acc: 0.8686 - val_loss: 0.3886 - val_acc: 0.8260\n",
            "Epoch 63/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.3072 - acc: 0.8713 - val_loss: 0.3977 - val_acc: 0.8330\n",
            "Epoch 64/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3046 - acc: 0.8727 - val_loss: 0.4000 - val_acc: 0.8290\n",
            "Epoch 65/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.3061 - acc: 0.8686 - val_loss: 0.4043 - val_acc: 0.8200\n",
            "Epoch 66/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3057 - acc: 0.8706 - val_loss: 0.3972 - val_acc: 0.8250\n",
            "Epoch 67/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.3021 - acc: 0.8732 - val_loss: 0.4009 - val_acc: 0.8270\n",
            "Epoch 68/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2959 - acc: 0.8757 - val_loss: 0.4225 - val_acc: 0.8180\n",
            "Epoch 69/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.3000 - acc: 0.8721 - val_loss: 0.4249 - val_acc: 0.8260\n",
            "Epoch 70/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2985 - acc: 0.8720 - val_loss: 0.4022 - val_acc: 0.8350\n",
            "Epoch 71/120\n",
            "10000/10000 [==============================] - 5s 482us/step - loss: 0.2978 - acc: 0.8726 - val_loss: 0.3947 - val_acc: 0.8320\n",
            "Epoch 72/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2968 - acc: 0.8761 - val_loss: 0.4012 - val_acc: 0.8330\n",
            "Epoch 73/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2962 - acc: 0.8732 - val_loss: 0.4259 - val_acc: 0.8290\n",
            "Epoch 74/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2879 - acc: 0.8790 - val_loss: 0.4342 - val_acc: 0.8290\n",
            "Epoch 75/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2890 - acc: 0.8748 - val_loss: 0.4460 - val_acc: 0.8180\n",
            "Epoch 76/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.2914 - acc: 0.8767 - val_loss: 0.4153 - val_acc: 0.8260\n",
            "Epoch 77/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2869 - acc: 0.8755 - val_loss: 0.4261 - val_acc: 0.8210\n",
            "Epoch 78/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.2879 - acc: 0.8776 - val_loss: 0.4430 - val_acc: 0.8230\n",
            "Epoch 79/120\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 0.2899 - acc: 0.8773 - val_loss: 0.4359 - val_acc: 0.8160\n",
            "Epoch 80/120\n",
            "10000/10000 [==============================] - 5s 496us/step - loss: 0.2843 - acc: 0.8815 - val_loss: 0.4391 - val_acc: 0.8210\n",
            "Epoch 81/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2882 - acc: 0.8792 - val_loss: 0.4585 - val_acc: 0.8180\n",
            "Epoch 82/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2807 - acc: 0.8781 - val_loss: 0.4626 - val_acc: 0.8260\n",
            "Epoch 83/120\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.2783 - acc: 0.8850 - val_loss: 0.4426 - val_acc: 0.8250\n",
            "Epoch 84/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2829 - acc: 0.8813 - val_loss: 0.4378 - val_acc: 0.8240\n",
            "Epoch 85/120\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.2789 - acc: 0.8829 - val_loss: 0.4391 - val_acc: 0.8290\n",
            "Epoch 86/120\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.2792 - acc: 0.8835 - val_loss: 0.4419 - val_acc: 0.8230\n",
            "Epoch 87/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2787 - acc: 0.8840 - val_loss: 0.4408 - val_acc: 0.8260\n",
            "Epoch 88/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2705 - acc: 0.8858 - val_loss: 0.4760 - val_acc: 0.8280\n",
            "Epoch 89/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2717 - acc: 0.8883 - val_loss: 0.4412 - val_acc: 0.8270\n",
            "Epoch 90/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2682 - acc: 0.8854 - val_loss: 0.4653 - val_acc: 0.8210\n",
            "Epoch 91/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2710 - acc: 0.8868 - val_loss: 0.4427 - val_acc: 0.8250\n",
            "Epoch 92/120\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.2719 - acc: 0.8839 - val_loss: 0.4355 - val_acc: 0.8230\n",
            "Epoch 93/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.2707 - acc: 0.8830 - val_loss: 0.4353 - val_acc: 0.8250\n",
            "Epoch 94/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2676 - acc: 0.8886 - val_loss: 0.4692 - val_acc: 0.8170\n",
            "Epoch 95/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2680 - acc: 0.8859 - val_loss: 0.4388 - val_acc: 0.8260\n",
            "Epoch 96/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2618 - acc: 0.8919 - val_loss: 0.4565 - val_acc: 0.8250\n",
            "Epoch 97/120\n",
            "10000/10000 [==============================] - 5s 470us/step - loss: 0.2628 - acc: 0.8924 - val_loss: 0.4443 - val_acc: 0.8230\n",
            "Epoch 98/120\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 0.2610 - acc: 0.8904 - val_loss: 0.4803 - val_acc: 0.8190\n",
            "Epoch 99/120\n",
            "10000/10000 [==============================] - 5s 459us/step - loss: 0.2594 - acc: 0.8895 - val_loss: 0.4561 - val_acc: 0.8260\n",
            "Epoch 100/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.2585 - acc: 0.8906 - val_loss: 0.4485 - val_acc: 0.8230\n",
            "Epoch 101/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2591 - acc: 0.8936 - val_loss: 0.4477 - val_acc: 0.8280\n",
            "Epoch 102/120\n",
            "10000/10000 [==============================] - 5s 501us/step - loss: 0.2556 - acc: 0.8932 - val_loss: 0.4904 - val_acc: 0.8170\n",
            "Epoch 103/120\n",
            "10000/10000 [==============================] - 5s 511us/step - loss: 0.2552 - acc: 0.8938 - val_loss: 0.4705 - val_acc: 0.8170\n",
            "Epoch 104/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.2552 - acc: 0.8921 - val_loss: 0.4770 - val_acc: 0.8270\n",
            "Epoch 105/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2542 - acc: 0.8957 - val_loss: 0.4676 - val_acc: 0.8290\n",
            "Epoch 106/120\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.2538 - acc: 0.8956 - val_loss: 0.5216 - val_acc: 0.8170\n",
            "Epoch 107/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2503 - acc: 0.8929 - val_loss: 0.4668 - val_acc: 0.8200\n",
            "Epoch 108/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2465 - acc: 0.8948 - val_loss: 0.4799 - val_acc: 0.8190\n",
            "Epoch 109/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2493 - acc: 0.8970 - val_loss: 0.4672 - val_acc: 0.8270\n",
            "Epoch 110/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2525 - acc: 0.8937 - val_loss: 0.4977 - val_acc: 0.8120\n",
            "Epoch 111/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.2488 - acc: 0.8949 - val_loss: 0.4705 - val_acc: 0.8190\n",
            "Epoch 112/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2536 - acc: 0.8928 - val_loss: 0.4741 - val_acc: 0.8270\n",
            "Epoch 113/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2519 - acc: 0.8954 - val_loss: 0.4773 - val_acc: 0.8250\n",
            "Epoch 114/120\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.2459 - acc: 0.8954 - val_loss: 0.4726 - val_acc: 0.8200\n",
            "Epoch 115/120\n",
            "10000/10000 [==============================] - 5s 477us/step - loss: 0.2457 - acc: 0.8997 - val_loss: 0.4763 - val_acc: 0.8280\n",
            "Epoch 116/120\n",
            "10000/10000 [==============================] - 5s 495us/step - loss: 0.2409 - acc: 0.9007 - val_loss: 0.4998 - val_acc: 0.8080\n",
            "Epoch 117/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2370 - acc: 0.8995 - val_loss: 0.5301 - val_acc: 0.8070\n",
            "Epoch 118/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2448 - acc: 0.8966 - val_loss: 0.4841 - val_acc: 0.8140\n",
            "Epoch 119/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2458 - acc: 0.8987 - val_loss: 0.5131 - val_acc: 0.8210\n",
            "Epoch 120/120\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2446 - acc: 0.9007 - val_loss: 0.4945 - val_acc: 0.8230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHTdHe9Bj0gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "c861a797-dad3-4570-ff3d-0a99562b098a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'],loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng0lBkjQsAbq6Dvf7U+4tAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzgdzEOdl6p2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('rnnmodel_120.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krnRA_fQmAB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_results = model.predict(([inputs_test,queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKoMjCb7mSNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74019df6-5185-4e1d-86f2-5bb70a3a2349"
      },
      "source": [
        "pred_results.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0rbaRLUmWtP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "9ad9282c-7b6f-498d-f357-b90f086df709"
      },
      "source": [
        "pred_results[0]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.9477611e-16, 7.1023988e-16, 7.7979891e-16, 7.1663005e-16,\n",
              "       5.9055513e-16, 5.5009898e-16, 6.0564920e-16, 5.8229163e-16,\n",
              "       6.0195238e-16, 7.0490362e-16, 5.5905599e-16, 5.7672303e-16,\n",
              "       6.1828529e-16, 6.5682345e-04, 6.1178643e-16, 6.0466585e-16,\n",
              "       6.1348781e-16, 7.1645779e-16, 5.9472391e-16, 6.0285553e-16,\n",
              "       6.3483118e-16, 5.1520530e-16, 6.5601564e-16, 6.7771567e-16,\n",
              "       7.1167454e-16, 6.4232171e-16, 6.3588547e-16, 5.8803738e-16,\n",
              "       5.9262231e-16, 6.3359970e-16, 5.8176325e-16, 6.3196556e-16,\n",
              "       5.9876452e-16, 9.9934322e-01, 6.7142401e-16, 6.7776215e-16,\n",
              "       6.4993039e-16, 6.2589329e-16], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm_UViPGmaX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_max = np.argmax(pred_results[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guURBmZ7mkrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02509764-3b35-4719-c35b-f9dba44aac04"
      },
      "source": [
        "val_max"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgNd4KIOmmT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key,val in tokenizer.word_index.items():\n",
        "  if val == val_max:\n",
        "    k = key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8eZnpBfmsrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf41f52f-6f07-4fc5-fb2d-d08b2f81d48b"
      },
      "source": [
        "k"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP3S87gWmtVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "06c3cdba-0d16-4aa3-ff8b-afecae17e354"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5C8DKuDmz39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "46361384-7857-406c-8138-5fba82cb293a"
      },
      "source": [
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden . \"\n",
        "my_story.split()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZdDAufonFN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c782da0-7e59-441f-cb39-6c8d4879a134"
      },
      "source": [
        "my_question = \"Is the football in the garden ?\"\n",
        "my_question.split()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwQuKGWlnLUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4voWRO9nZAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LorAb4xnd1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_result = model.predict(([my_story,my_ques]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BCru5Un1S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_max = np.argmax(pred_result[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go4KnV10n5uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key,val in tokenizer.word_index.items():\n",
        "  if val == val_max:\n",
        "    k = key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C2ssTtan_vW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a5a27d0-2b21-4f90-a87a-2b57c714053f"
      },
      "source": [
        "k"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZoHagCIoA2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}